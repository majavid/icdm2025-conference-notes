---
title: Day 2 â€“ Keynotes, Panels & Causality
---

# ğŸŒŸ Day 2 â€“ Takeaways from ICDM 2025, Washington, DC ğŸŒŸ

Another intense and inspiring day at ICDM 2025. A few highlights and reflections from today:

---

## 9:00â€“10:00 â€“ Keynote by Dr. John Quackenbush (Harvard University)

**Title:** *â€œWhy Networks Matter: Embracing Biological Complexityâ€*

My takeaway:
- Biology is **not easy**, and there is **no free lunch** theorem here.
- Heavy reliance on **simulated data** can be misleading for biologyâ€”Dr. Quackenbush clearly prefers real, messy data over clean simulations.

---

## 10:00â€“10:30 â€“ Meeting Dr. Jilles Vreeken

I met **Dr. Jilles Vreeken** in person, the Program Chair of ICDM 2025. He and **Dr. Wei Ding** (UMass Boston) have introduced several innovations into this yearâ€™s conference format. The presented stats are interesting and speak for themselves.

We had a great half-hour conversation about **causality**, especially:
- His seminal work on **MDL for causal inference**, and  
- His current projects on **causal invariants** and **domain adaptation**.

Very aligned with my own research interests.

---

## 10:30â€“12:00 â€“ Panel A: â€œThe Future of Probabilistic Modeling in Data Mining and AIâ€

The panel focused on challenges such as:
- **Scalability**
- **Explainability** (the *â€œwhyâ€* questions)
- The **mathematical foundations** of LLMs and other advanced models

In the Q&A, I raised the point that many of these concerns are *exactly* what **causality** is designed to addressâ€”yet causality was barely mentioned.

My takeaways from the responses:

- Research often **follows funding and mainstream trends**.  
- Formal **axiomatizations of causality** are still relatively young (only a few decades old), and there is uncertainty about what a full **â€œcausal turnâ€** in AI would imply.

---

## 15:00â€“16:00 â€“ Main Track S16: Interpretability

I attended three talks in the interpretability session. While technically interesting, I left wanting more:

- Little clarity on **how** the proposed models are interpretable.  
- Almost no discussion of **how interpretability was quantified**.

A reminder that **interpretability is often claimed but rarely operationalized**.

---

## 16:00â€“17:00 â€“ Main Track S15: Time Series I

One talk on **few-shot domain adaptation for time series** really caught my attentionâ€”a novel framework designed for few-shot *unsupervised* domain adaptation.

Iâ€™ll definitely be reading that paper more carefully for new ideas related to my work on **causal** and **robust TS** methods.

---

## Poster Session

The poster display was, unfortunately, the least engaging part of the day:
- Many authors were absent due to scheduling conflicts.

With better time allocation and fewer overlaps, this could be a much richer venue for deep, one-on-one scientific conversationsâ€”far more than the few minutes available in Q&A at the end of talks.

---

## Closing Thought

Overall, Day 2 reinforced for me how much room there is to bring **causal thinking**, **interpretability**, and **careful evaluation** into mainstream data mining and AI, especially in **biology** and **time series**.

More reflections coming soon. Stay tuned! ğŸš€ğŸ“Š
